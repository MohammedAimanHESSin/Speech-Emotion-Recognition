{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NcxU4OWDdgvPP70sLGAGscbyost9lCDL",
      "authorship_tag": "ABX9TyP7W/aV2e4SFu+ZspsqP89q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habiib1999/Speech-Emotion-Recognition/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BvgjiIyUmz0"
      },
      "source": [
        "# READ .WAV FILES AND LISTEN TO THEM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c6DcfABVZgB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "import re\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "# from entropy import spectral_entropy\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import itertools\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu2lbekgunFP"
      },
      "source": [
        "# Class : READER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF6pkUd7LsbH"
      },
      "source": [
        "#READER CLASS\n",
        "class Reader:\n",
        "  def __init__(self, ravdess_path, crema_path, savee_path, tess_path):\n",
        "    self.ravdess_path = ravdess_path\n",
        "    self.crema_path = crema_path\n",
        "    self.savee_path = savee_path\n",
        "    self.tess_path = tess_path\n",
        "\n",
        "  def readRavdess(self):\n",
        "    ravdess_directory_list = os.listdir(self.ravdess_path)\n",
        "\n",
        "    emotion_df = []\n",
        "\n",
        "    for dir in ravdess_directory_list:\n",
        "      actor = os.listdir(os.path.join(ravdess_path, dir))\n",
        "      for wav in actor:\n",
        "          info = wav.partition(\".wav\")[0].split(\"-\")\n",
        "          emotion = int(info[2])\n",
        "          emotion_df.append((emotion, os.path.join(ravdess_path, dir, wav)))\n",
        "\n",
        "\n",
        "    Ravdess_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Ravdess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "    Ravdess_df.Emotion.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
        "    #print(Ravdess_df.head())\n",
        "    return Ravdess_df\n",
        "\n",
        "  def readCrema(self):\n",
        "    emotion_df = []\n",
        "\n",
        "    for wav in os.listdir(crema_path):\n",
        "      info = wav.partition(\".wav\")[0].split(\"_\")\n",
        "      if info[2] == 'SAD':\n",
        "        emotion_df.append((\"sad\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'ANG':\n",
        "        emotion_df.append((\"angry\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'DIS':\n",
        "        emotion_df.append((\"disgust\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'FEA':\n",
        "        emotion_df.append((\"fear\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'HAP':\n",
        "        emotion_df.append((\"happy\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'NEU':\n",
        "        emotion_df.append((\"neutral\", crema_path + \"/\" + wav))\n",
        "      else:\n",
        "        emotion_df.append((\"unknown\", crema_path + \"/\" + wav))\n",
        "\n",
        "\n",
        "    Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "\n",
        "    #print(Crema_df.head())\n",
        "    return Crema_df\n",
        "\n",
        "  def readSavee(self):\n",
        "    savee_directiory_list = os.listdir(savee_path)\n",
        "    emotion_df = []\n",
        "    for wav in savee_directiory_list:\n",
        "      info = wav.partition(\".wav\")[0].split(\"_\")[1].replace(r\"[0-9]\", \"\")\n",
        "      emotion = re.split(r\"[0-9]\", info)[0]\n",
        "      if emotion=='a':\n",
        "        emotion_df.append((\"angry\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='d':\n",
        "        emotion_df.append((\"disgust\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='f':\n",
        "        emotion_df.append((\"fear\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='h':\n",
        "        emotion_df.append((\"happy\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='n':\n",
        "        emotion_df.append((\"neutral\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='sa':\n",
        "        emotion_df.append((\"sad\", savee_path + \"/\" + wav))\n",
        "      else:\n",
        "        emotion_df.append((\"surprise\", savee_path + \"/\" + wav))\n",
        "\n",
        "    Savee_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Savee_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "    #print(Savee_df.head())\n",
        "    return Savee_df\n",
        "\n",
        "  def readTess(self):  \n",
        "    tess_directory_list = os.listdir(tess_path)\n",
        "\n",
        "    emotion_df = []\n",
        "\n",
        "    for dir in tess_directory_list:\n",
        "      for wav in os.listdir(os.path.join(tess_path, dir)):\n",
        "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
        "        emo = info[2]\n",
        "        if emo == \"ps\":\n",
        "            emotion_df.append((\"surprise\", os.path.join(tess_path, dir, wav)))\n",
        "        else:\n",
        "            emotion_df.append((emo, os.path.join(tess_path, dir, wav)))\n",
        "\n",
        "\n",
        "    Tess_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Tess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "\n",
        "    #print(Tess_df.head())\n",
        "    return Tess_df\n",
        "\n",
        "  def read(self):\n",
        "    ravdess_dataset = self.readRavdess()\n",
        "    crema_dataset = self.readCrema()\n",
        "    savee_dataset = self.readSavee()\n",
        "    tess_dataset = self.readTess()\n",
        "    return ravdess_dataset, crema_dataset, savee_dataset, tess_dataset\n",
        "    \n",
        "  def concatenate(self,ravdess_dataset,crema_dataset,savee_dataset,tess_dataset):\n",
        "    concat_dataset = pd.concat([ravdess_dataset,crema_dataset,savee_dataset,tess_dataset], axis=0)\n",
        "    print(concat_dataset.shape)\n",
        "    return concat_dataset"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvkE1qr13QCJ"
      },
      "source": [
        "# Listen or plot Audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6ylJBlv3RL"
      },
      "source": [
        "def listenToAudio(path):\n",
        "  frequency_sampling, audio_signal = wavfile.read(path)\n",
        "  print('\\nSignal shape:', audio_signal.shape)\n",
        "  print('Signal Datatype:', audio_signal.dtype)\n",
        "  print('Signal duration:', round(audio_signal.shape[0] / \n",
        "  float(frequency_sampling), 2), 'seconds')\n",
        "  audio_signal = audio_signal / np.power(2, 15)\n",
        "  audio_signal = audio_signal [:100]\n",
        "  time_axis = 1000 * np.arange(0, len(audio_signal), 1) / float(frequency_sampling)\n",
        "  plt.plot(time_axis, audio_signal, color='blue')\n",
        "  plt.xlabel('Time (milliseconds)')\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.title('Input audio signal')\n",
        "  plt.show()\n",
        "  Audio(path)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaMAszE-K1ta",
        "outputId": "97b3bb2f-367b-49c0-b02c-86adba20654d"
      },
      "source": [
        "ravdess_path = \"/content/drive/MyDrive/emotionDataset/Ravdess/audio_speech_actors_01-24\"\n",
        "crema_path = \"/content/drive/MyDrive/emotionDataset/Crema\"\n",
        "savee_path = \"/content/drive/MyDrive/emotionDataset/Savee\"\n",
        "tess_path = \"/content/drive/MyDrive/emotionDataset/Tess\"\n",
        "\n",
        "reader = Reader(ravdess_path, crema_path, savee_path, tess_path)\n",
        "ravdess_dataset,crema_dataset,savee_dataset,tess_dataset = reader.read()\n",
        "concat_dataset = reader.concatenate(ravdess_dataset,crema_dataset,savee_dataset,tess_dataset)\n",
        "from sklearn.utils import shuffle\n",
        "concat_dataset = shuffle(concat_dataset)\n",
        "print(concat_dataset.head(10))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12162, 2)\n",
            "       Emotion                                               Path\n",
            "5965   disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "3121     happy  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "6330     happy  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "5270   neutral  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "6779     happy  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "4763   disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "3558       sad  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "593   surprise  /content/drive/MyDrive/emotionDataset/Tess/OAF...\n",
            "1528     happy  /content/drive/MyDrive/emotionDataset/Tess/YAF...\n",
            "2266     happy  /content/drive/MyDrive/emotionDataset/Crema/10...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXQ2g2btUEwg"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFTe1QMxUs2Y"
      },
      "source": [
        "# Create feature space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9EaBLUh92Kv"
      },
      "source": [
        "#reader = Reader()\n",
        "def energy(data, frame_length=2048, hop_length=512):\n",
        "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
        "    return en / frame_length\n",
        "def mel_spc(data, sr, frame_length=2048, hop_length=512, flatten: bool = False):\n",
        "    mel = librosa.feature.melspectrogram(y=data, sr=sr)\n",
        "    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrE2BcEDSv3r"
      },
      "source": [
        "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
        "    result = np.array([])\n",
        "\n",
        "    return np.mean(energy(data, frame_length, hop_length),axis=0),mel_spc(data, sr, frame_length, hop_length)\n",
        "\n",
        "\n",
        "def get_features(path, duration=2.5, offset=0.6):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
        "\n",
        "    energy_feature,mel_spec_feature = extract_features(data, sample_rate)\n",
        "\n",
        "    return np.array(energy_feature) , np.array(mel_spec_feature)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKpa4Gy9KAxF",
        "outputId": "a13a8a25-5f0c-49a1-97ee-264544ec2ddb"
      },
      "source": [
        "path = np.array(concat_dataset[\"Path\"])[657]\n",
        "data, sampling_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "print(len(data))\n",
        "print(data)\n",
        "print(sampling_rate)\n",
        "enrg = energy(data)\n",
        "mel_spec = mel_spc(data, sampling_rate)\n",
        "print(\"Energy shape: \", enrg.shape)\n",
        "print(\"Energy: \", enrg)\n",
        "print(\"MelSpectrogram shape: \", mel_spec.shape)\n",
        "print(\"MelSpectrogram : \", mel_spec)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34092\n",
            "[-0.07679766 -0.0756614  -0.05751546 ...  0.00024126  0.00014337\n",
            "  0.        ]\n",
            "22050\n",
            "Energy shape:  (67,)\n",
            "Energy:  [4.8163551e-04 3.0414090e-05 2.3859879e-05 7.7102071e-04 1.3334990e-03\n",
            " 1.6183523e-03 1.7789254e-03 1.1335369e-03 6.4440852e-04 4.5603770e-04\n",
            " 3.7313387e-04 3.2921013e-04 3.2670380e-04 3.4616533e-04 5.4895977e-04\n",
            " 1.2826503e-03 2.3805392e-03 3.4723037e-03 3.9064512e-03 4.2178491e-03\n",
            " 4.7476948e-03 4.9375570e-03 5.3153103e-03 5.3374292e-03 5.2532591e-03\n",
            " 4.6475576e-03 4.2079724e-03 3.2272479e-03 1.6557055e-03 9.0297230e-04\n",
            " 2.5838485e-04 1.0806081e-04 6.2823441e-05 2.1896602e-05 2.4189177e-07\n",
            " 1.1852012e-07 9.7806556e-08 6.5660997e-06 1.1994374e-04 4.1365516e-04\n",
            " 6.6685735e-04 7.3722657e-04 6.7886867e-04 5.3633685e-04 5.6321366e-04\n",
            " 1.1981376e-03 2.4483732e-03 3.9005042e-03 5.2773296e-03 6.1781430e-03\n",
            " 5.9975903e-03 4.6594786e-03 3.0077444e-03 1.3953907e-03 2.7087214e-04\n",
            " 5.7553611e-06 6.1523588e-07 1.2171058e-05 2.5469450e-05 3.4303637e-05\n",
            " 3.8254479e-05 2.7815133e-05 1.4499465e-05 5.6219892e-06 1.6210271e-06\n",
            " 2.5872612e-07 5.6765582e-08]\n",
            "MelSpectrogram shape:  (67, 128)\n",
            "MelSpectrogram :  [[1.1581956e-01 1.4161426e-01 1.4023468e-01 ... 4.3837397e-05\n",
            "  1.3938063e-04 1.5140885e-04]\n",
            " [2.8850332e-02 3.6304168e-02 3.5760425e-02 ... 1.4799049e-05\n",
            "  3.8030266e-05 3.8064634e-05]\n",
            " [1.4262733e-03 2.4812709e-04 2.8924472e-04 ... 2.2848085e-06\n",
            "  6.8818457e-07 6.3062039e-08]\n",
            " ...\n",
            " [5.9458558e-03 1.2400446e-03 3.8203956e-03 ... 1.2941568e-05\n",
            "  9.8507044e-06 2.7003500e-07]\n",
            " [3.9372290e-03 8.9599146e-04 6.7403447e-04 ... 2.3461475e-06\n",
            "  1.1887751e-06 4.1678391e-08]\n",
            " [3.2512829e-04 3.9828764e-04 1.2597288e-03 ... 1.1261980e-06\n",
            "  3.4081251e-07 3.4390570e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjcVp6qE9H8Q",
        "outputId": "fc0ae7b8-f791-49e6-e4c4-3326a0e4448d"
      },
      "source": [
        "extracted_data_energy, extracted_data_mel_spec = [], []\n",
        "extracted_data_energy_labels, extracted_data_mel_spec_labels = [], []\n",
        "print(\"Feature processing...\")\n",
        "for path, emotion, ind in zip(concat_dataset.Path, concat_dataset.Emotion, range(concat_dataset.Path.shape[0])):\n",
        "    energy_feature,mel_spec_feature = get_features(path)\n",
        "    if ind % 100 == 0:\n",
        "        print(f\"{ind} samples has been processed...\")\n",
        "    extracted_data_energy.append(energy_feature)      \n",
        "    extracted_data_energy_labels.append(emotion)\n",
        "    extracted_data_mel_spec.append(mel_spec_feature)      \n",
        "    extracted_data_mel_spec_labels.append(emotion)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature processing...\n",
            "0 samples has been processed...\n",
            "100 samples has been processed...\n",
            "200 samples has been processed...\n",
            "300 samples has been processed...\n",
            "400 samples has been processed...\n",
            "500 samples has been processed...\n",
            "600 samples has been processed...\n",
            "700 samples has been processed...\n",
            "800 samples has been processed...\n",
            "900 samples has been processed...\n",
            "1000 samples has been processed...\n",
            "1100 samples has been processed...\n",
            "1200 samples has been processed...\n",
            "1300 samples has been processed...\n",
            "1400 samples has been processed...\n",
            "1500 samples has been processed...\n",
            "1600 samples has been processed...\n",
            "1700 samples has been processed...\n",
            "1800 samples has been processed...\n",
            "1900 samples has been processed...\n",
            "2000 samples has been processed...\n",
            "2100 samples has been processed...\n",
            "2200 samples has been processed...\n",
            "2300 samples has been processed...\n",
            "2400 samples has been processed...\n",
            "2500 samples has been processed...\n",
            "2600 samples has been processed...\n",
            "2700 samples has been processed...\n",
            "2800 samples has been processed...\n",
            "2900 samples has been processed...\n",
            "3000 samples has been processed...\n",
            "3100 samples has been processed...\n",
            "3200 samples has been processed...\n",
            "3300 samples has been processed...\n",
            "3400 samples has been processed...\n",
            "3500 samples has been processed...\n",
            "3600 samples has been processed...\n",
            "3700 samples has been processed...\n",
            "3800 samples has been processed...\n",
            "3900 samples has been processed...\n",
            "4000 samples has been processed...\n",
            "4100 samples has been processed...\n",
            "4200 samples has been processed...\n",
            "4300 samples has been processed...\n",
            "4400 samples has been processed...\n",
            "4500 samples has been processed...\n",
            "4600 samples has been processed...\n",
            "4700 samples has been processed...\n",
            "4800 samples has been processed...\n",
            "4900 samples has been processed...\n",
            "5000 samples has been processed...\n",
            "5100 samples has been processed...\n",
            "5200 samples has been processed...\n",
            "5300 samples has been processed...\n",
            "5400 samples has been processed...\n",
            "5500 samples has been processed...\n",
            "5600 samples has been processed...\n",
            "5700 samples has been processed...\n",
            "5800 samples has been processed...\n",
            "5900 samples has been processed...\n",
            "6000 samples has been processed...\n",
            "6100 samples has been processed...\n",
            "6200 samples has been processed...\n",
            "6300 samples has been processed...\n",
            "6400 samples has been processed...\n",
            "6500 samples has been processed...\n",
            "6600 samples has been processed...\n",
            "6700 samples has been processed...\n",
            "6800 samples has been processed...\n",
            "6900 samples has been processed...\n",
            "7000 samples has been processed...\n",
            "7100 samples has been processed...\n",
            "7200 samples has been processed...\n",
            "7300 samples has been processed...\n",
            "7400 samples has been processed...\n",
            "7500 samples has been processed...\n",
            "7600 samples has been processed...\n",
            "7700 samples has been processed...\n",
            "7800 samples has been processed...\n",
            "7900 samples has been processed...\n",
            "8000 samples has been processed...\n",
            "8100 samples has been processed...\n",
            "8200 samples has been processed...\n",
            "8300 samples has been processed...\n",
            "8400 samples has been processed...\n",
            "8500 samples has been processed...\n",
            "8600 samples has been processed...\n",
            "8700 samples has been processed...\n",
            "8800 samples has been processed...\n",
            "8900 samples has been processed...\n",
            "9000 samples has been processed...\n",
            "9100 samples has been processed...\n",
            "9200 samples has been processed...\n",
            "9300 samples has been processed...\n",
            "9400 samples has been processed...\n",
            "9500 samples has been processed...\n",
            "9600 samples has been processed...\n",
            "9700 samples has been processed...\n",
            "9800 samples has been processed...\n",
            "9900 samples has been processed...\n",
            "10000 samples has been processed...\n",
            "10100 samples has been processed...\n",
            "10200 samples has been processed...\n",
            "10300 samples has been processed...\n",
            "10400 samples has been processed...\n",
            "10500 samples has been processed...\n",
            "10600 samples has been processed...\n",
            "10700 samples has been processed...\n",
            "10800 samples has been processed...\n",
            "10900 samples has been processed...\n",
            "11000 samples has been processed...\n",
            "11100 samples has been processed...\n",
            "11200 samples has been processed...\n",
            "11300 samples has been processed...\n",
            "11400 samples has been processed...\n",
            "11500 samples has been processed...\n",
            "11600 samples has been processed...\n",
            "11700 samples has been processed...\n",
            "11800 samples has been processed...\n",
            "11900 samples has been processed...\n",
            "12000 samples has been processed...\n",
            "12100 samples has been processed...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "6L2-JWKU8z_b",
        "outputId": "2de94167-97a1-4675-87da-2c08ab939bc0"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/energy_features.csv\"\n",
        "extracted_df = pd.DataFrame(extracted_data_energy)\n",
        "extracted_df[\"labels\"] = extracted_data_energy_labels\n",
        "extracted_df.to_csv(features_path, index=False)\n",
        "extracted_df.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001820</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000259</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000807</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001235</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001565</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0   labels\n",
              "0  0.001820  disgust\n",
              "1  0.000259    happy\n",
              "2  0.000807    happy\n",
              "3  0.001235  neutral\n",
              "4  0.001565    happy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "eH56PdCrlLGc",
        "outputId": "757643d6-2de5-4200-cde5-90507aa50b80"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/mel_spec_features.csv\"\n",
        "extracted_df = pd.DataFrame(extracted_data_mel_spec)\n",
        "extracted_df[\"labels\"] = extracted_data_mel_spec_labels\n",
        "extracted_df.to_csv(features_path, index=False)\n",
        "extracted_df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.037761945, 0.16695678, 0.13421017, 0.04242...</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.056401253, 0.06830928, 0.062207915, 0.0446...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.032273035, 0.032312907, 0.049332775, 0.030...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.009226999, 0.030860092, 0.014787596, 0.006...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.09210995, 0.04682401, 0.02212438, 0.300461...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0   labels\n",
              "0  [[0.037761945, 0.16695678, 0.13421017, 0.04242...  disgust\n",
              "1  [[0.056401253, 0.06830928, 0.062207915, 0.0446...    happy\n",
              "2  [[0.032273035, 0.032312907, 0.049332775, 0.030...    happy\n",
              "3  [[0.009226999, 0.030860092, 0.014787596, 0.006...  neutral\n",
              "4  [[0.09210995, 0.04682401, 0.02212438, 0.300461...    happy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQZ2fcrmugxs",
        "outputId": "085ed053-c7fa-4233-bd79-2be432325858"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/energy_features.csv\"\n",
        "extracted_df = pd.read_csv(features_path)\n",
        "extracted_df.head()\n",
        "print(len(extracted_df.loc[4][0]))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}