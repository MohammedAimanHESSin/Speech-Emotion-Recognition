{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NcxU4OWDdgvPP70sLGAGscbyost9lCDL",
      "authorship_tag": "ABX9TyPw1v7n9j8DD0irBzjAHU3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habiib1999/Speech-Emotion-Recognition/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BvgjiIyUmz0"
      },
      "source": [
        "# READ .WAV FILES AND LISTEN TO THEM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c6DcfABVZgB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "import re\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "# from entropy import spectral_entropy\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import itertools\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu2lbekgunFP"
      },
      "source": [
        "# Class : READER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF6pkUd7LsbH"
      },
      "source": [
        "#READER CLASS\n",
        "class Reader:\n",
        "  def __init__(self, ravdess_path, crema_path, savee_path, tess_path):\n",
        "    self.ravdess_path = ravdess_path\n",
        "    self.crema_path = crema_path\n",
        "    self.savee_path = savee_path\n",
        "    self.tess_path = tess_path\n",
        "\n",
        "  def readRavdess(self):\n",
        "    ravdess_directory_list = os.listdir(self.ravdess_path)\n",
        "\n",
        "    emotion_df = []\n",
        "\n",
        "    for dir in ravdess_directory_list:\n",
        "      actor = os.listdir(os.path.join(ravdess_path, dir))\n",
        "      for wav in actor:\n",
        "          info = wav.partition(\".wav\")[0].split(\"-\")\n",
        "          emotion = int(info[2])\n",
        "          emotion_df.append((emotion, os.path.join(ravdess_path, dir, wav)))\n",
        "\n",
        "\n",
        "    Ravdess_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Ravdess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "    Ravdess_df.Emotion.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
        "    #print(Ravdess_df.head())\n",
        "    return Ravdess_df\n",
        "\n",
        "  def readCrema(self):\n",
        "    emotion_df = []\n",
        "\n",
        "    for wav in os.listdir(crema_path):\n",
        "      info = wav.partition(\".wav\")[0].split(\"_\")\n",
        "      if info[2] == 'SAD':\n",
        "        emotion_df.append((\"sad\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'ANG':\n",
        "        emotion_df.append((\"angry\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'DIS':\n",
        "        emotion_df.append((\"disgust\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'FEA':\n",
        "        emotion_df.append((\"fear\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'HAP':\n",
        "        emotion_df.append((\"happy\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'NEU':\n",
        "        emotion_df.append((\"neutral\", crema_path + \"/\" + wav))\n",
        "      else:\n",
        "        emotion_df.append((\"unknown\", crema_path + \"/\" + wav))\n",
        "\n",
        "\n",
        "    Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "\n",
        "    #print(Crema_df.head())\n",
        "    return Crema_df\n",
        "\n",
        "  def readSavee(self):\n",
        "    savee_directiory_list = os.listdir(savee_path)\n",
        "    emotion_df = []\n",
        "    for wav in savee_directiory_list:\n",
        "      info = wav.partition(\".wav\")[0].split(\"_\")[1].replace(r\"[0-9]\", \"\")\n",
        "      emotion = re.split(r\"[0-9]\", info)[0]\n",
        "      if emotion=='a':\n",
        "        emotion_df.append((\"angry\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='d':\n",
        "        emotion_df.append((\"disgust\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='f':\n",
        "        emotion_df.append((\"fear\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='h':\n",
        "        emotion_df.append((\"happy\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='n':\n",
        "        emotion_df.append((\"neutral\", savee_path + \"/\" + wav))\n",
        "      elif emotion=='sa':\n",
        "        emotion_df.append((\"sad\", savee_path + \"/\" + wav))\n",
        "      else:\n",
        "        emotion_df.append((\"surprise\", savee_path + \"/\" + wav))\n",
        "\n",
        "    Savee_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Savee_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "    #print(Savee_df.head())\n",
        "    return Savee_df\n",
        "\n",
        "  def readTess(self):  \n",
        "    tess_directory_list = os.listdir(tess_path)\n",
        "\n",
        "    emotion_df = []\n",
        "\n",
        "    for dir in tess_directory_list:\n",
        "      for wav in os.listdir(os.path.join(tess_path, dir)):\n",
        "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
        "        emo = info[2]\n",
        "        if emo == \"ps\":\n",
        "            emotion_df.append((\"surprise\", os.path.join(tess_path, dir, wav)))\n",
        "        else:\n",
        "            emotion_df.append((emo, os.path.join(tess_path, dir, wav)))\n",
        "\n",
        "\n",
        "    Tess_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Tess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "\n",
        "    #print(Tess_df.head())\n",
        "    return Tess_df\n",
        "\n",
        "  def read(self):\n",
        "    ravdess_dataset = self.readRavdess()\n",
        "    crema_dataset = self.readCrema()\n",
        "    savee_dataset = self.readSavee()\n",
        "    tess_dataset = self.readTess()\n",
        "    return ravdess_dataset, crema_dataset, savee_dataset, tess_dataset\n",
        "    \n",
        "  def concatenate(self,ravdess_dataset,crema_dataset,savee_dataset,tess_dataset):\n",
        "    concat_dataset = pd.concat([ravdess_dataset,crema_dataset,savee_dataset,tess_dataset], axis=0)\n",
        "    print(concat_dataset.shape)\n",
        "    return concat_dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvkE1qr13QCJ"
      },
      "source": [
        "# Listen or plot Audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6ylJBlv3RL"
      },
      "source": [
        "def listenToAudio(path):\n",
        "  frequency_sampling, audio_signal = wavfile.read(path)\n",
        "  print('\\nSignal shape:', audio_signal.shape)\n",
        "  print('Signal Datatype:', audio_signal.dtype)\n",
        "  print('Signal duration:', round(audio_signal.shape[0] / \n",
        "  float(frequency_sampling), 2), 'seconds')\n",
        "  audio_signal = audio_signal / np.power(2, 15)\n",
        "  audio_signal = audio_signal [:100]\n",
        "  time_axis = 1000 * np.arange(0, len(audio_signal), 1) / float(frequency_sampling)\n",
        "  plt.plot(time_axis, audio_signal, color='blue')\n",
        "  plt.xlabel('Time (milliseconds)')\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.title('Input audio signal')\n",
        "  plt.show()\n",
        "  Audio(path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaMAszE-K1ta",
        "outputId": "afe40f39-9d1a-4c9e-fa57-c13339634b70"
      },
      "source": [
        "ravdess_path = \"/content/drive/MyDrive/emotionDataset/Ravdess/audio_speech_actors_01-24\"\n",
        "crema_path = \"/content/drive/MyDrive/emotionDataset/Crema\"\n",
        "savee_path = \"/content/drive/MyDrive/emotionDataset/Savee\"\n",
        "tess_path = \"/content/drive/MyDrive/emotionDataset/Tess\"\n",
        "\n",
        "reader = Reader(ravdess_path, crema_path, savee_path, tess_path)\n",
        "ravdess_dataset,crema_dataset,savee_dataset,tess_dataset = reader.read()\n",
        "concat_dataset = reader.concatenate(ravdess_dataset,crema_dataset,savee_dataset,tess_dataset)\n",
        "from sklearn.utils import shuffle\n",
        "concat_dataset = shuffle(concat_dataset)\n",
        "print(concat_dataset.head(10))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12162, 2)\n",
            "       Emotion                                               Path\n",
            "3659      fear  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "496    disgust  /content/drive/MyDrive/emotionDataset/Ravdess/...\n",
            "693   surprise  /content/drive/MyDrive/emotionDataset/Tess/YAF...\n",
            "2766     happy  /content/drive/MyDrive/emotionDataset/Tess/OAF...\n",
            "2753     happy  /content/drive/MyDrive/emotionDataset/Tess/OAF...\n",
            "2610     happy  /content/drive/MyDrive/emotionDataset/Tess/OAF...\n",
            "6009   disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "4330     happy  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "2432   disgust  /content/drive/MyDrive/emotionDataset/Tess/OAF...\n",
            "2260       sad  /content/drive/MyDrive/emotionDataset/Crema/10...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXQ2g2btUEwg"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFTe1QMxUs2Y"
      },
      "source": [
        "# Create feature space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9EaBLUh92Kv"
      },
      "source": [
        "#reader = Reader()"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}